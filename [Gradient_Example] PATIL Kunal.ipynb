{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exam/Project  \n",
    "## MSc AIS July 2020\n",
    "## Deadline July, 30, 23h59.\n",
    "### A simple example  of a gradient descent method  by hand (batch  method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  PATIL Kunal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.datasets.samples_generator import make_regression \n",
    "import pylab\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We're going to solve a  Least Squares Problem with a cost function defined as following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$J(\\Theta)=\\frac{1}{2*m} \\sum_{i=1}^{m} (h_\\Theta(x_i)−y_i)^2$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$$J(\\Theta)=\\frac{1}{2*m} \\sum_{i=1}^{m} (h_\\Theta(x_i)−y_i)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### where \n",
    "### i) x_i is the ith sample\n",
    "### ii) m is the total number of training examples \n",
    "#### and hθ(x(i)) is the hypothesis function defined like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$h_\\Theta(x_i)=\\Theta_0  + \\Theta_1 x_i$$\n",
       "###### Constant (intercept) and Slope\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "$$h_\\Theta(x_i)=\\Theta_0  + \\Theta_1 x_i$$\n",
    "###### Constant (intercept) and Slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def Gradient_Method(alpha, x, y, eps=0.0001, max_iter=1000, steps=10):\n",
    "    HasConverged = False\n",
    "    iter = 0\n",
    "    m = x.shape[0] # number of samples\n",
    "\n",
    "    print(\"Number of Samples:\", m)\n",
    "\n",
    "    # initial value for theta  : chosen randomly\n",
    "    # Theta=(Theta0[0],Theta1[0]) in IR^2\n",
    "    # Theta0[0] -> t0 in IR\n",
    "    # Theta1[0] -> t1 in IR\n",
    "    t0 = np.random.random(x.shape[1])\n",
    "    t1 = np.random.random(x.shape[1])\n",
    "    print(\"Initial Value of Thetao[0] =\", t0)\n",
    "    print(\"Initial Value of Theta1[0] =\", t1)\n",
    "\n",
    "    # The total error, J(theta)  is defined as\n",
    "    J = sum([(t0 + t1*x[i] - y[i])**2 for i in range(m)])\n",
    "    print(\"Total Initial Error J: \", J)\n",
    "\n",
    "    # The Iteration Loop\n",
    "    while not HasConverged:\n",
    "        # for each training sample, compute the gradient (d/d_theta j(theta))\n",
    "        # following: \n",
    "        \n",
    "        grad0 = 1.0/m * sum([(t0 + t1*x[i] - y[i]) for i in range(m)]) \n",
    "        grad1 = 1.0/m * sum([(t0 + t1*x[i] - y[i])*x[i] for i in range(m)])\n",
    "\n",
    "        # We update the theta_temp\n",
    "        temp0 = t0 - alpha * grad0        \n",
    "        temp1 = t1 - alpha * grad1\n",
    "\n",
    "\n",
    "        # We update theta\n",
    "        t0 = temp0\n",
    "        t1 = temp1\n",
    "\n",
    "        # We compute Mean Squared Error\n",
    "        e = sum([(t0 + t1*x[i] - y[i])**2 for i in range(m)]) \n",
    "\n",
    "        if abs(J-e) <= eps:\n",
    "            print('Converged, iterations: ', iter)\n",
    "            HasConverged = True\n",
    "            \n",
    "        if (iter % steps ==0): print(\"Iter: \", iter, \n",
    "                                     \" Error:\",e, \n",
    "                                     \" J-e:\",abs(J-e))    \n",
    "    \n",
    "        J = e      # We update error \n",
    "        iter += 1  # We update iter\n",
    "    \n",
    "        if iter == max_iter:\n",
    "            print('Max interactions exceeded!')\n",
    "            converged = True\n",
    "\n",
    "    return t0,t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = (100, 1) y.shape = (100,)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "#   We create the Data     \n",
    "    x, y = make_regression(n_samples=100, n_features=1, n_informative=1, \n",
    "                        random_state=0, noise=35) \n",
    "    print('x.shape = %s y.shape = %s' %(x.shape, y.shape))\n",
    "    \n",
    "# We choose some hyperparameters  \n",
    "    alpha = 0.2 # learning rate\n",
    "    ep = 0.01 # convergence criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples: 100\n",
      "Initial Value of Thetao[0] = [0.24322514]\n",
      "Initial Value of Theta1[0] = [0.99156682]\n",
      "Total Initial Error J:  [320903.52799641]\n",
      "Iter:  0  Error: [260888.04008634]  J-e: [60015.48791007]\n",
      "Iter:  25  Error: [139898.85563137]  J-e: [5.94314904]\n",
      "Iter:  50  Error: [139879.10221092]  J-e: [0.01926749]\n",
      "Converged, iterations:  54\n",
      "Computed value\n",
      "Theta0 = [-3.02146703]       Theta1 = [42.81762957]\n",
      "Intercept = -2.8496363946075403 Slope = 43.20424388023939\n",
      "Error on Slope [0.38661431]\n",
      "Error on Intercept [0.17183064]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD4CAYAAAAEhuazAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8GearUAAAgAElEQVR4nO3deZRV1ZU/8O+uopCxw2AlkUJA80NE5KelFaFDVgyaBG1JW07oT2ObtIZII6s1WSgGE4dohNgtxu4gwV9MJ8sEZRCiYBqhicEYUKoUoyiFOCBVsBoUaBkqUMPuP+q98g33vvfufffec4fvZy0W1HnTqVfFvufts885oqogIqJkqTDdASIiCh6DPxFRAjH4ExElEIM/EVECMfgTESVQD9MdKNXxxx+vI0aMMN0NIqJIaWxs/FBVq3PbIxP8R4wYgYaGBtPdICKKFBHZYdXOtA8RUQIx+BMRJRCDPxFRAjH4ExElEIM/EVECRabah4iomBWvtuCB1U3YdaAVQwb0xsxJo1BfW2O6W6HE4E9EsbDi1Rbc/tTraG3rAAC0HGjF7U+9DgC8AFhg2oeIYuGB1U3dgT+tta0DD6xuMtSjcGPwJ6JY2HWg1VF70jH4E1EsDBnQ21F70jH4E1EszJw0Cr2rKrPaeldVYuakUYZ6FG6c8CWiWEhP6rLapzQM/kQUG/W1NQz2JWLah4gogRj8iYgSiGkfIiqIq2bjicGfiGxx1Wx8Me1DRLa4aja+OPInIltcNWstDqkwjvyJyBZXzeZLp8JaDrRC8UkqbMWrLaa75giDPxHZ4qrZfHFJhTHtQ0S2uGo2X1xSYQz+RFQQV81mGzKgN1osAn3UUmFM+xARORCXVJgnwV9EHhORPSLyRkbbIBFZIyJvp/4emHHb7SKyXUSaRGSSF30gIgpCfW0N7r90LGoG9IYAqBnQG/dfOjZyn45EVct/EpEvATgE4Neqenqq7ScA9qnqHBGZBWCgqt4mIqcBWATgHABDAKwFcIqqdtg8PQCgrq5OGxoayu4rEYVfHEopw0JEGlW1Lrfdk5y/qq4XkRE5zRcD+HLq378C8DyA21LtT6jqUQDvich2dF0INnjRFyKKtqiuKo7aBcvPnP9nVHU3AKT+/nSqvQbAzoz7Nafa8ojIVBFpEJGGvXv3+thVIgqLKJZSRrH238SEr1i0WeaeVHWhqtapal11dbXP3SKiMIhiKaUfF6wVr7Zgwpx1OGnWKkyYs87zC4mfwf+/ReQEAEj9vSfV3gzgxIz7DQWwy8d+EFGERHFVsdcXrCA+SfgZ/J8GcF3q39cB+F1G+1UicpyInARgJICXfewHEUVIFEspvb5gpT9JHN76J7S+swmA96kvTyZ8RWQRuiZ3jxeRZgB3ApgDYLGIXA/gAwBXAICqbhGRxQDeBNAOYHqxSh8iSo4oriqeOWlU1iQ1UN4Fa9O8G9C2573ur4fd+gxExNPUlyelnkFgqScRhVm51T6qiuOOOw5tbW1Z7UNuWICqwUMBdK0peHHWeY765WupJxFR0rndBqOjowM9euSH4uHfegj49P/p/trr1Be3dyAi4/yubAmj1tZWiEhe4H/77behqnhoxuW+riLmyJ+IjIrqoi63PvzwQ1iVru/Zsyer3e8N9TjyJyKjorioy413330XIpIX+A8fPgxVtbwg+InBn4iMiuKiLic2bdoEEcHnPve5rPb29naoKvr06WOkXwz+RGRUFBd1lWLVqlUQEZxzzjndbRUVFejs7ISqorKyssCj/cfgT0RGRXFRVyELFy6EiGDy5MndbWPHjoWqoqOjAyJWO9wEjxO+RGTLbe26k8f5vagrqN02J0yYgD//+c9ZbZdddhmWLl3q+Wt5gcGfiCy5rcJx8zgvK1syg/2APlU49Nd2tHWqo+/BCauR/K233oq5c+d68vx+YdqHiCy5rcIxWb2TuyHa/iNt3YHf676ISF7g/9a3vgVVDX3gBxj8iciG2yock9U7VhceL/uiqpZB/5577oGq4rHHHnP1vCYw+BORJbdVOCard0oN6k770tbWBhFBRUV2yHzooYegqvjBD37g6PnCgMGfiCy5rcIxWb1TSlB30pfdu3dDRNCzZ8+s9meffRaqiuFfujyy21Iw+BORpfraGtx/6VjH+8u4fZwXrC48VZWCAb2rHPXlpZdegohgyJAhWe1n3vwLLH+lGRdeeGEkj27MxC2diShWyintfOyxx3D99dfntdf806/Qo/9gAF2fHO6/dCweWN2EFos0k5ttl/3ELZ2JYiioGvYocVM2Om3aNCxYsCCvfcT3lkF7HJfVlq4Wivq2FAz+RBGVtN0w/XDKKafg7bffzmt/qnEnvr/8DdvKofTF1mrkH5VtKZjzJ4qopOyG6Yd0uWZu4FdVqCr+5bltBUtG05+yorwtBUf+RBEV9bSDCXb76uTOfRZ6D9MBPopnDWdi8CeKqKinHYJUatBPs3tvK0WyqoX8PnDFT0z7EBnm9ghDu7TDxFOrI1t77jWr1bjAJ+kdO3bv7b9OOSOywT4XR/5EBpUzaWuVdph4ajWWNbYkfhLY6Ug/V9RTOqVgnT+RQRPmrPO0Vtzr54uS1tZWy1Oxxo0bh40bNxroUTjY1fkz7UNkkNeTtkmcBN62bRtEJC/wT548Gaqa6MBfCIM/kUF2k7MVIq5y9nE9EtHK4sWLISIYNSq7tHLevHlQVTzzzDOGehYNDP5EBllNLAJAh6qr/WKiXnteim9/+9sQEVx55ZVZ7Rs3boSq4uabbzbUs2jxfcJXRN4HcBBAB4B2Va0TkUEAngQwAsD7AKao6n6/+0IURr2qKronaAVA7ixceuFWqZONx/X45PkG9qnCnV8fE4uJyv79++PQoUN57R999BEGDRpkoEf+CGrLjqBG/hNV9cyMSYdZAP5LVUcC+K/U10SJkq702X+krbvNrvyilJx9+vkOtH7yfH9t6yy3m8alyzVzA39HRwdUNXaBP6idQk2lfS4G8KvUv38FoN5QPyhh3NbU+6HUU6eA0nL2cdvuoViNfu7BKnEQ5M8wiDp/BfCciCiAn6vqQgCfUdXdAKCqu0Xk01YPFJGpAKYCwLBhwwLoKsVZoZp6IPia7lIrcErN2XtZ6WNyt9Bya/SjLMhqrSCC/wRV3ZUK8GtEZGupD0xdKBYCXXX+fnWQksFuVHXX01twtL0z8IVRdlsIDOxThT49ezgOvF5t91DqwjOvLxBJDvppQW7Z4fvnJlXdlfp7D4DlAM4B8N8icgIApP7e43c/iOxGTwda24ykS2ZOGoWqyuyAV1UpuPPrY/DirPPw3pyL8OKs80oOqF5V+pSSevAyN+12C4Y4CrJay9fgLyJ9RaR/+t8AvgbgDQBPA7gudbfrAPzOz34QAc5HT4EsjMqNbWXEOq+OTywl9eBFbppBP1+QR2D6nfb5DIDlqR9wDwC/VdX/FJFNABaLyPUAPgBwhc/9IMLMSaOy0hlA16iqV1VFVsVNmt8Lox5Y3YS2zuwg19apjso6c3mxy2QpqQe3uenDhw+jX79+lrclNeDnCmqnUF9H/qr6rqqekfozRlXvS7V/pKrnq+rI1N/7/OwHEWA/qrrz62OMLIwK61YMpaQenK4kbmxshIhYBv4kj/RN4q6elCiFRlVBV7eEZT9+q4nb9AHldu+H3aeo3Avmj3/8Y8yePTvvNa+55ho8/vjj/n1TVBSDPyWeqbLGUgOon+wqe+6/dGzBXUCLbXk8ePBg7NuX/4F+0aJFuOqqq3z4TsgpBn9KNJOHoIdhz/hCE7elnCeQex+7cs0dO3ZYrtUxuZ4g6Rj8KdHKCX5eMH0MoFfzDnZBv729HZWV+RvXAWYvvMRdPSnhgp50DdP2EkD5W0AXK9e0C/xA/LajiBoGf0q0IPe/L7YwysSFwe2iIi9q9MNa7ZQUTPtQ6ASZBw5y0rXYSNdECsTpvIOXWzD4We3EuYTieIYvhUpuHhjoCsZ+rXJMv2YQgeKkWassF/AK7ANhWM7e9WPfHbuf9WVn1+APW/e6/nmY+B0KM7szfDnyp1AxMQEb1KRroZFuWFMgfm62ZvWpY+Kp1VjW2FLWJyDTk/hRwZw/hUpYg6AXCuXXy5l78Hqu4PDhw4Htu1NfW5O1id0ftu4texI4zr9DXmLwp1CJ8wHkhTbtcjvx6uXumhs2bDC+BYMXgTvOv0NeYvCnUIn7AeS5I910GsLtbo5elEveeuutEBF84QtfyGo/+eSTA993Z0CfKst2J4E77r9DXmHOn0LF61WvUar6cDP3UM5I2S6f/+CDD+KWW25x1A8vrHi1BYf+2p7XXlUpjgJ3GFZORwGDP4WOVxOwUVhBWu7FyU25pF3Qf/PNNzF69OjuOYSgA6fVFtcA0LdnD8evb3rldBQw7UOxFfYVpF7k6yeeWl1yu90k7rFjx6Cq3YHfqzkEp+w+rfxPa/5ZC1Q+jvwptoKs+nAzgndTkpj7OkeO5adJAGDRSztRN3wQ6mtrHJVrmiyTDMsW10nBkT/FVlBVH25Hy04vTlavY3UCGQB0qOKSs4Y6Ltc0WSbJidpgMfhTbAUVTNyml5xenKxex8qOuZOxY+7kvPZSKndMlkkGeX4tMe1DMRZU5ZDb0bLTfYWKPZ9VwAecrcY1fcAMJ2qDw+BPsRZE5ZDbXLXTi5Pd69gF/eG3rUSNwxE7yySTgxu7EZVgwpx1thuv2Y2WvU5ZZF6AOo/9FTvnXW55v+G3rfStDxQ93NiNQidKC7AKpXaCGi3X19bgLy+/iDtvvNLy9uWvNIf6/YzSzzsJGPzJiCgswMpULLXjd6766quvxqJFiyxvO/WO33eP8MP43gHR+3knAat9yIiwL8DKZaoMMb0wKzfw9ztjEobfthLDb1sZ6vctLWo/7yTgyJ+MiNq2u0FPhNotzPrsNQ/guKGj89pbDrRixastoR1FR+3nnQQc+ZMRUdx2N731cvrwlQdWN3m+7YHdFgytra1QVZx8+lm2jw1qG4ZC7M4WiOLPO+4Y/MmIKK7mtFphe8uTm3HHitfLfu5ih6f06tULgPX7lmY6jVJopXPQP2+vD7iJI2PBX0QuEJEmEdkuIrNM9YPMiOJqTqu8tQL4zcYPXAcXpydmpd83OybTKMX2BQrq521yc7ooMZLzF5FKAD8D8FUAzQA2icjTqvqmif6QGWGuTrFiF1gVcLzxWTln49bX1uCB1U2W1UcVIsZy/8Xy+kH9vHmGb2lMjfzPAbBdVd9V1WMAngBwsaG+UEI5TQ0Uyk+XOuL26mxcu/RPh6qxUW5Y8vqcXC6NqeBfA2BnxtfNqbYsIjJVRBpEpGHv3r2BdY7iz01qYOakUbAerxcPcF4fiJ5Oo1RaTQ4byv2HZR4nLBehsDMV/K3+D+X9D1DVhapap6p11dXWh1YQueGm7ry+tgbXjB+W98trF+BaW1tLDvpuJijra2vQ6XBrZj+FZR4nLBehsDNV598M4MSMr4cC2GWoL5RAblMD99aPRd3wQQXr/devX49zzz3X8vFWo/xyVr+G7QCUMMzjcHO60pgK/psAjBSRkwC0ALgKwNWG+kIJVE7QtAtw1157LR5//HHLxxRK7ZQ6QWm1N47pLZjDKgwXobAzkvZR1XYANwFYDeAtAItVdYuJvlD0eFHD7WVqIJ3ayQ38l19+eUk5/VI+hdjNUQAIRaqFosfY9g6q+iyAZ029PkWTVxuEeZEasCvXXLt2Lc4///ySn6eUTyGFPh28OOs8BntyjHv7xERStsv1soY79wKQnuwt9jx2Qf/gwYPo16+foz4ApZ2eFebyxaT87sUNg38MJGm7XC+DoNP3zS7oD79tJXpXVWLt2/+D+lrnwb+UTyFhm9hNS9LvXtww+MdA3Fc0Zo4sK0TQYZFDTwdBJ6PQUt+3QkG/0OOcKDZBGdaJ3bj/7sUZg38MhDklUK7ckaVV4E8HQaej0GLvm13QH3HbyvxFKQWezwthLV+M8+9e3DH4x0BYUwJesBpZAkClCDpVs4LghDnrHI1C7d639+dOhszN70u6asfuPF+/3+8wli/G+Xcv7rilcwzEeUWj3QiyUxXvzbkoq9LF6Sg0933bMXcydsydnHe/3HLNOL/fTvG9iC6O/GMgrCkBL9iNLD/VuwoT5qzL+n6djkLra2vQ1nYMU8adbHm7XX1+nN9vp/heRJe42VTKhLq6Om1oaDDdDQpYbh4fAKoqBBCgreOT393eVZW47OwaLGtsyZsUtVr0tHnzZtTW1lq+ZlT+TxCVQkQaVbUut51pHwo1q83C+vXqkRX4ga7c/h+27i262vXee++FiFgGfrc7bBJFEUf+FDknzVplWW0jAN6bc5HlYz71qU/h448/zmu/4YYb8Oijj3rbQaIQsRv5M+dPkeMkt29XrvnCCy/gi1/8oud9I4oKBn8qKmzL90tZ8GQX9A8dOoS+ffv63sekC9vvDOVj8KeCrBZO3fLkZjTs2Id76+0PEnfy/E6DRKEKk3LOxvVbUgIit3yIBub8qSC7BU0CYN6VZ5b1n9mqkgcABvapwp1fHxPYgehBBGWr79WuEinq7H5nagb0xouzzjPQo2RjtQ+5YrdASoGyz4m1W727/0hbyYeQl3s2rpuzfN1wc2xkVHHLh2hg8KeCCi3TL/c/c6HHFwuMXh2IHlRQTlJA5AHq0cDgTwXNnDQq78DytHL/Mxd7vFVg9CroF3qNQu1uJSkgcsuHaGDwp4Lqa2twzfhheRcAL/4zF3t8OjC2t7d7HvRzX6PUdreSFBCtFubFcW4j6ljtQ0XdWz8WdcMHeT4pWl9bg7uf2YL9R9rybhMA3zjtON+rd4LaJz9pe+CEcQdSysZqHzLKqgrm0GvP4aP/fDjvvv3797dcpetFH6IalKPcdwoGV/hSKGWOiBvn/zOO7nwj7z7f//73cd9997l6/lKCY1RHqaynp3Iw+JNxl5w11LJ9w4YNGD9+vOvnjXtwtKtU+t7i1wDE43sk/zD4k6ecpCHs8vkHDx5Ev37OD0LPFffzZe0qkjpUY3WRI38w+JNruYF+4qnVWfvp2420g9qCwU0ZZ5Ry6HYb3AHxusiRP1jqSa5YrYz9zcYPCi6Y8qtc047TMs6gVvt6xap8NFPLgVZMmLMutP0nsxj8yRWrlIpd+P7z7ecHGvTTnNbWR20LhnQ9faXNJykg/BcwMse34C8id4lIi4hsTv35u4zbbheR7SLSJCKT/OoD+aeUFbClHojuF6eLjaK4BUN9bQ3+dcoZBT8BhPkCRub4nfOfp6r/ktkgIqcBuArAGABDAKwVkVNUNX+HLwotu3yzAHjfIuADZrZVdlLG6fQA+LDILJe1mwMI8wWMzDCR9rkYwBOqelRV3wOwHcA5BvpBZchNqah2YsfcyZaBPypn40Z5C4b62hq8OOs81CRoDyEqj9/B/yYR+YuIPCYiA1NtNQB2ZtynOdWWR0SmikiDiDTs3bvX566SE+mUyqd7tmHH3Mn44Cd/n3X7CSecEJmgnxaHPWmifAGjYJW1vYOIrAXwWYubZgPYCOBDdM0D/gjACar6jyLyMwAbVPXx1HP8AsCzqrqs0Gtxe4dweeWVV3D22Wfntc+YMQMPP5y/NUPSmCwZjVK5KvnPl+0dVPUrJb74owBWpr5sBnBixs1DAewqpx8UnEcffRRTp07Na3/qqadwySWXGOiRe34FSdMri6O6XQUFy7cJXxE5QVV3p768BEB605anAfxWRB5E14TvSAAv+9UP8saNN96In//853nt77zzDk4++WQDPSpPoQANlLf7ZtxXFlM8+Fnt8xMRORNdaZ/3AXwHAFR1i4gsBvAmgHYA01npExyno91x48bh5Zfzr82tra3o1auXn10tidvRu12AvuvpLTja3lnWqN2usqblQCvOvPs5HGjt2sLazVnFRF7xLfir6rUFbrsPgLttGsk1J+mIoLZgKEc56RW7AJ0OzJmcjtoLbbuQ+fz7j7Rh5tLXur9mnp6CxBW+CVLKCtagt2AoRzkrcp2WPjqpk7equLFbg9vWobj7mS2R2laC4oHBP0EKrWCNUtBPK2dFrl1J5MA+VZb3d3KxsCoZLfQO7j/SFqltJSgeuKtnxJRToWKVjrDafgEIV3rHTjkrcu2OVQTgybGOuRU3E+ass00F2eGqXPITg3+ElFtCmHlerd9BP4ha83LP3y1UEul132dOGoWZS15DW2f2+1tVKejbs4flXANX5ZKfeIZvhNiNHmsG9MaLs84r+nhVRUVFfqavR48eaGvLDz6FFAruVufy9q6qtFwtW+5FIkoLmla82oK7nt6SV+0DWH/aiNrqYgonnuEbA25z3EeOHEHfvn3z2qdNm4b58+c77kexTyCl1rl7sRgqSguaivU1KhcxigcG/whxmuNuaWnB0KH55+P+8pe/xDe/+U3X/SgW3Eu9SHEx1CeidBGjeGC1T4SUumnXSy+9BBHJC/wbN26EqpYV+IHin0BKPUErivvnE8UFg3+EFNt1csmSJRARjB8/Putxe/bsgapi3LhxnvSjWHAv9SLl9JhFIvIO0z4RY5UeWLp0Ka644oq8+x49ehQ9e/b0vA/Fqmzsyihz+11utQ4RucfgH2Fz587FrFmz8tr9ruAqJbiXksMu9SIRdVGqSKLkYKlnBM2bNw/f/e5389qj8rOMKjdB3EnZK5Ef7Eo9mfOPkDVr1kBEsgJ/r169Qr0FQ1ykg7jT/XfK2X+IyE8M/hHw5JNPQkTwta99rbtt9uzZUFW0trIyJghugzgrmiismPMPsfnz52P69OlZbY2NjTjrrLMM9Si53AbxcvYfIvITR/4ho6q4++67ISJZgX/btm1QVQZ+Q9yWpfJAdQorBv+Q6OzsxPTp01FRUYG77roLAFBdXY2WlhaoKkaOHGm2gwnnNogXW5tBZArTPoa1tbXh6quvxtKlS7vbxowZgxdeeAEDBw402DPKVE5ZKrduoDBi8DfkyJEjuPDCC7F+/frutokTJ2LlypXo06ePwZ6RHQZxihOmfQK2b98+jB49Gn379u0O/FdeeSWOHTuGdevWMfATUSAY/APS0tKCQYMGYfDgwdi6dSsAYMaMGejo6MATTzyBqirr4wOJiPzA4O+zpqam7h029+/fDwC455570NnZiYcfftjycBUiIr8x5++ThoYGfP7zn89qe+SRR3DjjTca6pFZ3N+GKFwY/D22du1afPWrX81qW7JkCS6//HJDPTLPixO7iMhbDP4eWbJkCaZMmZLVtnbtWpx//vm+v3bYR9U8sYsofBj8y7RgwQJMmzYtq23Tpk2oq8vbRM+XIB2FUTX3tyEKn7JmG0XkChHZIiKdIlKXc9vtIrJdRJpEZFJG+9ki8nrqtodFRMrpgwmqih/96EcQkazA39TUBFW1DfxudoUsJgq7RvLELqLwKbfU5A0AlwJYn9koIqcBuArAGAAXAJgvIum18Y8AmApgZOrPBWX2ITCdnZ2YMWMGKioq8MMf/hAAMHjwYDQ3N0NVccopp9g+1q8g7XZUveLVFkyYsw4nzVqFCXPWlX0RKoT72xCFT1lpH1V9CwAsBu8XA3hCVY8CeE9EtgM4R0TeB/A3qroh9bhfA6gH8Pty+uG3trY2fOMb38DixYu720aPHo0//elPGDRoUEnP4Vfqw82ukUGnipJyYhdRlPiV868BsDHj6+ZUW1vq37ntlkRkKro+JWDYsGHe97KII0eO4KKLLsLzzz/f3Xbuuefi2WefdbwS16+tfd2cg2tiApZbIxCFS9G0j4isFZE3LP5cXOhhFm1aoN2Sqi5U1TpVrauuri7WVc/s378fY8aMQd++fbsD/5QpU3Ds2DE8//zzrrZg8Cv1UWjXSLvUDidgiajoyF9Vv+LieZsBnJjx9VAAu1LtQy3aQ6GlpQVnnHEGPvroo+62m266CT/96U/LXonrZ+rDalRdKLXDA0aIyK+0z9MAfisiDwIYgq6J3ZdVtUNEDorIeAAvAfgHAP/mUx9Ktm3bNowalT0Cv+eee3DHHXdYzWe4FmTqo1Bqx02qiIjipazgLyKXoCt4VwNYJSKbVXWSqm4RkcUA3gTQDmC6qqYjzTQA/wGgN7omeo1N9jY2NuaVZc6fPz+vbj+KCqV2OAFLROVW+ywHsNzmtvsA3GfR3gDg9HJet1zr1q3LW3n75JNP5q3QjbJiqR1OwBIlW6K2lFy2bBlEJCvwr1mzBqoaq8APsLaeiApLxPYOCxcuxHe+852sNrstGOKCqR0iKiT2wf/LX/4y/vjHP3Z/vXXr1rzJ3bhiaoeI7MQ+7TN16lSMGjUKO3fuhKomJvATERUiqrZrrEKlrq5OGxoaTHeDiChSRKRRVfNy3LEf+RMRUT4GfyKiBGLwJyJKIAZ/IqIEYvAnIkogBn8iogSK9SIvPw5MJyKKg9gG/6CPKiQiipLYpn38OjCdiCgOYhv8eVQhEZG92AZ/uyMJeVQhEVGMgz/3sycishfbCV/uZ09EZC+2wR/gfvZERHZim/YhIiJ7DP5ERAnE4E9ElEAM/kRECcTgT0SUQAz+REQJxOBPRJRAZQV/EblCRLaISKeI1GW0jxCRVhHZnPqzIOO2s0XkdRHZLiIPi4iU0wciInKu3JH/GwAuBbDe4rZ3VPXM1J8bM9ofATAVwMjUnwvK7AMRETlUVvBX1bdUteQ9kkXkBAB/o6obVFUB/BpAfTl9ICIi5/zc3uEkEXkVwMcA7lDVFwDUAGjOuE9zqs2SiExF16cEDBs2zMeuRgNPJiMirxQN/iKyFsBnLW6araq/s3nYbgDDVPUjETkbwAoRGQPAKr+vdq+tqgsBLASAuro62/slAU8mIyIvFQ3+qvoVp0+qqkcBHE39u1FE3gFwCrpG+kMz7joUwC6nz59EhU4mY/AnIqd8KfUUkWoRqUz9+2R0Tey+q6q7ARwUkfGpKp9/AGD36YEy8GQyIvJSuaWel4hIM4C/BbBKRFanbvoSgL+IyGsAlgK4UVX3pW6bBuD/A9gO4B0Avy+nD0nBk8mIyEtlTfiq6nIAyy3alwFYZvOYBgCnl/O6STRz0qisnD/Ak8mIyL1YH+YSJzyZjIi8xOAfITyZjIi8wr+wXAwAAAKWSURBVL19iIgSiMGfiCiBGPyJiBKIwZ+IKIEY/ImIEki6NtcMPxHZC2CH6X544HgAH5ruhCH83pOJ37tZw1W1OrcxMsE/LkSkQVXrit8zfvi983tPmjB/70z7EBElEIM/EVECMfgHb6HpDhjE7z2Z+L2HEHP+REQJxJE/EVECMfgTESUQg78BIvKAiGwVkb+IyHIRGWC6T0ERkStEZIuIdIpIKEvgvCQiF4hIk4hsF5FZpvsTJBF5TET2iMgbpvsSNBE5UUT+ICJvpX7f/9l0n3Ix+JuxBsDpqvp/AWwDcLvh/gTpDQCXAlhvuiN+Sx1l+jMAFwI4DcD/E5HTzPYqUP8B4ALTnTCkHcD3VHU0gPEApoftZ8/gb4CqPqeq7akvNyL7UPtYU9W3VLXJdD8Ccg6A7ar6rqoeA/AEgIsN9ykwqroewL6id4whVd2tqq+k/n0QwFsAQnUYB4O/ef8InmMcVzUAdmZ83YyQBQDyn4iMAFAL4CWzPcnGk7x8IiJrAXzW4qbZqvq71H1mo+vj4W+C7JvfSvneE0Is2lhbnSAi0g9d55nfrKofm+5PJgZ/n6jqVwrdLiLXAZgM4HyN2WKLYt97gjQDODHj66EAdhnqCwVMRKrQFfh/o6pPme5PLqZ9DBCRCwDcBuDvVfWI6f6QbzYBGCkiJ4lITwBXAXjacJ8oACIiAH4B4C1VfdB0f6ww+Jvx7wD6A1gjIptFZIHpDgVFRC4RkWYAfwtglYisNt0nv6Qm9W8CsBpdE36LVXWL2V4FR0QWAdgAYJSINIvI9ab7FKAJAK4FcF7q//hmEfk7053KxO0diIgSiCN/IqIEYvAnIkogBn8iogRi8CciSiAGfyKiBGLwJyJKIAZ/IqIE+l+wUY8WNT4e1wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well Done!\n",
      "Wall time: 316 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# We call gradient descent, this gives approximation \n",
    "# of theta0 and theta1\n",
    "theta0, theta1 = Gradient_Method(alpha, x, y, ep, max_iter=1000,\n",
    "                                     steps=25)\n",
    "print(\"Computed value\")\n",
    "print(('Theta0 = %s       Theta1 = %s') %(theta0, theta1)) \n",
    "\n",
    "# We check a good approximation of the \"exact\" value\n",
    "# with scipy linear regression \n",
    "slope, intercept, r_value, p_value, slope_std_error = stats.linregress(x[:,0], y)\n",
    "print(('Intercept = %s Slope = %s') %(intercept, slope))\n",
    "print(\"Error on Slope\", slope-theta1)\n",
    "print(\"Error on Intercept\", intercept-theta0)\n",
    "    \n",
    "# We plot  the data and the line we have computed, i.e.: Y= Theta0 + Theta1 * X\n",
    "for i in range(x.shape[0]):\n",
    "        y_predict = theta0 + theta1*x \n",
    "\n",
    "pylab.plot(x,y,'o')\n",
    "pylab.plot(x,y_predict,'k-')\n",
    "pylab.show()\n",
    "print(\"Well Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some remarks\n",
    "#### I have chosen the function  Gradient_Method because: \n",
    "#### it is not really well written, so it can be improved\n",
    "#### First the initial value of  Theta0 and Theta1 are chosen strictly randomly, which is the worst case we can do. We can do a better choice.\n",
    "#### Second, the \"gradient\"  is computed with the full dataset (i.e. the full set of avalaible data), which has a hugh cost again, we can do better, at least initially. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea: when you will have your code, \n",
    "## try different (and growing) values of m (number of samples). And use %%time to compare\n",
    "## Examples: \n",
    "### (Small): m=100, m=1000, m=5000 (quite quick)\n",
    "### (Medium): m=100000, m=200000, m=500000  (become slow)\n",
    "### (Large): m=1000000, m=2000000, m=10000000 (can be very slow, be careful)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exercice 1\n",
    "#### Here we choose really randomly the inital  value of Theta0 and Theta1, they are ### what we call Theta0[0] and Theta1[0] in the classical iterative algorithms \n",
    "####(Theta0[i+1] ,Theta1[i+1])=(Theta0[i] ,Theta1[i]) - Lambda * Grad(F(Theta0[i] ,Theta1[i]))\n",
    "\n",
    "#### Propose another method, fast, efficient and usefull (i.e. with a low complexity)\n",
    "#### Implement it, test it, justify it (here)\n",
    "#### Please call your function Gradient_Method_Ex1\n",
    "\n",
    "## Computations without Changing anything:\n",
    "\n",
    "| Sample  | Theta 0 Ini | Theta 1 Ini | Theta 0 Fin  | Theta 1 Fin | Steps | eps  | alpha | time    | Error    | J minus E | Ini J    | Iter |\n",
    "| ------- | ----------- | ----------- | ------------ | ----------- | ----- | ---- | ----- | ------- | -------- | --------- | -------- | ---- |\n",
    "| 100     | 0.69677183  | 0.50446904  | \\-2.81902057 | 43.13937829 | 25    | 0.01 | 0.01  | 864ms   | 139860.8 | 0.014     | 325171.3 | 643  |\n",
    "| 1000    | 0.19175141  | 0.63705183  | 0.89824038   | 81.96178564 | 25    | 0.01 | 0.01  | 10.3s   | 1205909  | 0.01418   | 7661495  | 844  |\n",
    "| 10000   | 0.27220497  | 0.67021344  | \\-0.30422893 | 9.24977633  | 25    | 0.01 | 0.01  | 1 m 23s | 12266130 | 0.015277  | 12990605 | 722  |\n",
    "| 100000  | 0.7876183   | 0.91829285  | 0.20800278   | 79.3211362  | 25    | 0.01 | 0.01  | 22m 30s | 1.23E+08 | 0.015248  | 7.34E+08 | 1047 |\n",
    "| 1000000 | NC          | NC          | NC           | NC          | 25    | 0.01 | 0.01  | \\>4hr   | NC       | NC        | NC       | NC   |\n",
    "\n",
    "\n",
    "### TRIALS: (Random Theta values)\n",
    "\n",
    "#### Trial 1: Adding 1/2 in J(theta) equation\t\t\t\n",
    "| Sample  | Theta 0 Ini | Theta 1 Ini | Theta 0 Fin  | Theta 1 Fin | Steps | eps  | alpha | time   | Error    | J minus E | Ini J    | Iter |\n",
    "| ------- | ----------- | ----------- | ------------ | ----------- | ----- | ---- | ----- | ------ | -------- | --------- | -------- | ---- |\n",
    "| 100     | 0.26423659  | 0.8329894   | \\-2.8399727  | 43.1868806  | 25    | 0.01 | 0.01  | 187ms  | 139864.2 | 0.953441  | 16113369 | 73   |\n",
    "| 1000    | 0.78457948  | 0.00230946  | 0.90321327   | 81.97729987 | 25    | 0.01 | 0.01  | 1.26s  | 1205910  | 0.297354  | 3.88E+09 | 92   |\n",
    "| 10000   | 0.76362757  | 0.09555822  | \\-0.30386276 | 9.25493195  | 25    | 0.01 | 0.01  | 9.58s  | 12266130 | 0.03086   | 6.55E+10 | 81   |\n",
    "| 100000  | 0.6993037   | 0.89488509  | 0.20796707   | 79.32271831 | 25    | 0.01 | 0.01  | 2m 24s | 1.23E+08 | 0.091903  | 3.67E+13 | 111  |\n",
    "| 1000000 | NC          | NC          | NC           | NC          | 25    | 0.01 | 0.01  | \\>2hr  | NC       | NC        | NC       | NC   |\n",
    "\n",
    "###### Can see decrease in number of iterations and required time as compared to given case computation above but still for higher number of samples time complexity was greater.\n",
    "\n",
    "#### Trial 2: Adding 1/2 in J(theta) equation and 1/2m in grad equation\t\t\t\n",
    "| Sample  | Theta 0 Ini | Theta 1 Ini | Theta 0 Fin  | Theta 1 Fin | Steps | eps  | alpha | time         | Error    | J minus E | Ini J    | Iter |\n",
    "| ------- | ----------- | ----------- | ------------ | ----------- | ----- | ---- | ----- | ------------ | -------- | --------- | -------- | ---- |\n",
    "| 100     | 0.09677304  | 0.67187717  | \\-2.83551289 | 43.17685846 | 25    | 0.01 | 0.01  | 292ms        | 139860.6 | 0.052189  | 161819.8 | 142  |\n",
    "| 1000    | 0.98845101  | 0.09647489  | 0.90225831   | 81.97431877 | 25    | 0.01 | 0.01  | 2.23s        | 1205909  | 0.019245  | 3876505  | 182  |\n",
    "| 10000   | 0.33200292  | 0.27307335  | \\-0.30399664 | 9.25393412  | 25    | 0.01 | 0.01  | 19.1s        | 12266130 | 0.022888  | 6529845  | 159  |\n",
    "| 100000  | 0.13108116  | 0.57314066  | 0.20796755   | 79.32239664 | 25    | 0.01 | 0.01  | 4m 50s       | 1.23E+08 | 0.082243  | 3.7E+08  | 221  |\n",
    "| 1000000 | NC          | NC          | NC           | NC          | 25    | 0.01 | 0.01  | Not Computed | NC       | NC        | NC       | NC   |\n",
    "\n",
    "###### Decrease in number of iterations and required time as compared to given case computation but time as well as number of iterations were approx twice from trial 1.\n",
    "\n",
    "#### Trial 3: Implementing Stochastic gradient descent method (alpha = 0.1)\n",
    "\n",
    "| Sample | Theta 0 Ini | Theta 1 Ini | Theta 0 Fin  | Theta 1 Fin | Steps | eps  | alpha | time  | Error    | J minus E | Ini J    | Iter |\n",
    "| ------ | ----------- | ----------- | ------------ | ----------- | ----- | ---- | ----- | ----- | -------- | --------- | -------- | ---- |\n",
    "| 100    | 0.41820816  | 0.66624716  | \\-2.93550066 | 43.0088309  | 25    | 0.01 | 0.1   | 269ms | 139865.5 | 0.077908  | 323724.4 | 94   |\n",
    "| 1000   | 0.06467464  | 0.50666308  | 0.88241652   | 81.98624243 | 25    | 0.01 | 0.1   | 1.66s | 1205911  | 0.506662  | 7681474  | 92   |\n",
    "| 10000  | 0.45631235  | 0.63151107  | \\-0.30913241 | 9.25612137  | 25    | 0.01 | 0.1   | 16.2s | 12266130 | 0.029617  | 13000157 | 79   |\n",
    "| 100000 | 0.13131007  | 0.07067743  | 0.20632711   | 79.32273849 | 25    | 0.01 | 0.1   | 4m 8s | 1.23E+08 | 0.250569  | 7.48E+08 | 116  |\n",
    "\n",
    "###### With change in alpha value from 0.01 to 0.1, better results observed at 0.1. Though complexity remain unchanged as for trial 2, but number of iterations decreased to half for each dataset.\n",
    "\n",
    "#### Trial 4: Implementing Stochastic gradient descent method (alpha = 0.2)\n",
    "\n",
    "| Sample | Theta 0 Ini | Theta 1 Ini | Theta 0 Fin  | Theta 1 Fin | Steps | eps  | alpha | time   | Error    | J minus E | Ini J    | Iter |\n",
    "| ------ | ----------- | ----------- | ------------ | ----------- | ----- | ---- | ----- | ------ | -------- | --------- | -------- | ---- |\n",
    "| 100    | 0.01284637  | 0.12560546  | \\-2.84283898 | 43.1929847  | 25    | 0.01 | 0.2   | 154ms  | 139862   | 1.023874  | 28.60349 | 36   |\n",
    "| 1000   | 0.46746621  | 0.95911915  | 0.90425964   | 81.9803357  | 25    | 0.01 | 0.2   | 686ms  | 1205999  | 47.90874  | 3228.657 | 46   |\n",
    "| 10000  | 0.49961333  | 0.02967459  | \\-0.30387266 | 9.25568592  | 25    | 0.01 | 0.2   | 5.15s  | 12266140 | 5.615929  | 9734.549 | 40   |\n",
    "| 100000 | 0.87006852  | 0.61139427  | 0.20796283   | 79.32295089 | 25    | 0.01 | 0.2   | 1m 24s | 1.23E+08 | 0.051426  | 53801.19 | 54   |\n",
    "\n",
    "###### With change in alpha from 0.1 to 0.2, again better results obtained at 0.2. Number of iterations were less but for higher samples (10000000) the time required was almost more than 5 hrs (whole night). With increase in learning rate for large samples, the chances of bouncing steps could be possible.\n",
    "\n",
    "### Proposed Methods: (Fix Theta value = 1 )\n",
    "\n",
    "#### Using Numpy\n",
    "##### Instead of doing summation of the samples in dataset, using dot product in numpy which gives more faster computation. As x.shape is (m, 1) and y is (m,)\n",
    "##### To match the dimensions for dot product, we add another column at first position in x array.\n",
    "##### Total Error is calculated with batch method and after getting the gradient value with batch method only we are calculating mean square error.\n",
    "\n",
    "| Sample   | Theta 0 Ini | Theta 1 Ini | Theta 0 Fin  | Theta 1 Fin | Steps | eps  | alpha | time   | Error    | J minus E | Ini J    | Iter |\n",
    "| -------- | ----------- | ----------- | ------------ | ----------- | ----- | ---- | ----- | ------ | -------- | --------- | -------- | ---- |\n",
    "| 100      | 1           | 1           | \\-2.54148803 | 42.24628171 | 25    | 0.01 | 0.01  | 128ms  | 700.0854 | 0.015733  | 1604.873 | 373  |\n",
    "| 1000     | 1           | 1           | 0.71293834   | 80.97454472 | 25    | 0.01 | 0.01  | 201ms  | 603.7451 | 0.015449  | 3804.711 | 448  |\n",
    "| 10000    | 1           | 1           | \\-0.19251681 | 8.259133489 | 25    | 0.01 | 0.01  | 643ms  | 613.9573 | 0.012953  | 647.6119 | 214  |\n",
    "| 100000   | 1           | 1           | 0.22457997   | 78.33093248 | 25    | 0.01 | 0.01  | 11.1s  | 615.0954 | 0.012327  | 3665.684 | 436  |\n",
    "| 1000000  | 1           | 1           | 0.01986483   | 80.20895416 | 25    | 0.01 | 0.01  | 1m 28s | 611.2015 | 0.012492  | 3825.865 | 437  |\n",
    "| 10000000 | 1           | 1           | 0.01218412   | 74.51985562 | 25    | 0.01 | 0.01  | 15m 5s | 612.7972 | 0.010805  | 3387.409 | 429  |\n",
    "\n",
    "##### By implementing and testing this method, time and number of iterations are better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def Gradient_Method_Ex1(alpha, x, y, eps=0.0001, max_iter=1000, steps=10):\n",
    "    \n",
    "    HasConverged = False\n",
    "    iter = 0        \n",
    "    m = x.shape[0] # number of samples    \n",
    "    x = np.c_[ np.ones(m), x]\n",
    "    theta = np.ones(2)    \n",
    "    \n",
    "    print(\"Number of Samples:\", m)\n",
    "\n",
    "    # initial value for theta  : chosen randomly\n",
    "    # Theta=(Theta0[0],Theta1[0]) in IR^2\n",
    "    # Theta0[0] -> t0 in IR\n",
    "    # Theta1[0] -> t1 in IR\n",
    "    \n",
    "    t0 = theta[0]\n",
    "    t1 = theta[1]\n",
    "    print(\"Initial Value of Thetao[0] =\", t0)\n",
    "    print(\"Initial Value of Theta1[0] =\", t1)    \n",
    "    \n",
    "    # The total error, J(theta)  is defined as\n",
    "    J = (1/(2*m)) * sum((np.dot(x, theta) - y)**2)\n",
    "    print(\"Total Initial Error J: \", J)\n",
    "    \n",
    "    # The Iteration Loop\n",
    "    while not HasConverged:        \n",
    "        \n",
    "        grad = (1/m) * np.dot(x.transpose(), (np.dot(x, theta) - y))\n",
    "        theta = theta - alpha * grad\n",
    "        \n",
    "        # We compute Mean Squared Error\n",
    "        e = (1/(2*m)) * sum((np.dot(x, theta) - y)**2)        \n",
    "        if abs(J-e) <= eps:\n",
    "            print('Converged, iterations: ', iter)\n",
    "            HasConverged = True\n",
    "\n",
    "        if (iter % steps ==0): print(\"Iter: \", iter, \n",
    "                                     \" Error:\",e, \n",
    "                                     \" J-e:\",abs(J-e))    \n",
    "\n",
    "        J = e      # We update error \n",
    "        iter += 1  # We update iter                \n",
    "        \n",
    "        if iter == max_iter:\n",
    "            print('Max interactions exceeded!')\n",
    "            converged = True        \n",
    "            \n",
    "    return theta[0], theta[1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = (1000000, 1) y.shape = (1000000,)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "#   We create the Data     \n",
    "    x, y = make_regression(n_samples=1000000, n_features=1, n_informative=1, \n",
    "                        random_state=0, noise=35) \n",
    "    print('x.shape = %s y.shape = %s' %(x.shape, y.shape))    \n",
    "    \n",
    "# We choose some hyperparameters  \n",
    "    alpha = 0.01 # learning rate\n",
    "    ep = 0.01 # convergence criteria     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples: 1000000\n",
      "Initial Value of Thetao[0] = 1.0\n",
      "Initial Value of Theta1[0] = 1.0\n",
      "Total Initial Error J:  3825.865119039858\n",
      "Iter:  0  Error: 3215.0723770384925  J-e: 610.7927420013657\n",
      "Iter:  25  Error: 624.023703760562  J-e: 3.1512911237659864\n",
      "Iter:  50  Error: 610.6553939478855  J-e: 0.016259744245076035\n",
      "Converged, iterations:  53\n",
      "Computed value\n",
      "Theta0 = 0.006888979406598816       Theta1 = 80.92081108535702\n",
      "Intercept = 0.0010496294035382547 Slope = 81.1922665739614\n",
      "Error on Slope 0.2714554886043885\n",
      "Error on Intercept -0.0058393500030605614\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well Done!\n",
      "Wall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# We call gradient descent, this gives approximation \n",
    "# of theta0 and theta1\n",
    "\n",
    "\n",
    "theta0, theta1 = Gradient_Method_Ex1(alpha, x, y, ep, max_iter=1000,\n",
    "                                     steps=25)\n",
    "print(\"Computed value\")\n",
    "print(('Theta0 = %s       Theta1 = %s') %(theta0, theta1)) \n",
    "\n",
    "# We check a good approximation of the \"exact\" value\n",
    "# with scipy linear regression \n",
    "slope, intercept, r_value, p_value, slope_std_error = stats.linregress(x[:,0], y)\n",
    "print(('Intercept = %s Slope = %s') %(intercept, slope))\n",
    "print(\"Error on Slope\", slope-theta1)\n",
    "print(\"Error on Intercept\", intercept-theta0)\n",
    "    \n",
    "# We plot  the data and the line we have computed, i.e.: Y= Theta0 + Theta1 * X\n",
    "for i in range(x.shape[1]):\n",
    "        y_predict = theta0 + theta1*x \n",
    "\n",
    "pylab.plot(x,y,'o')\n",
    "pylab.plot(x,y_predict,'k-')\n",
    "pylab.show()\n",
    "print(\"Well Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 2\n",
    "#### Here we \"upgrade\", in the function Gradient_Method, the gradient using the \"full batch\", i.e. the full set of avalaible data\n",
    "#### Implement  the \"minibatch\" idea.\n",
    "#### Please call your function Gradient_Method_Ex2\n",
    "\n",
    "## Computations with mini_batch gradient descent implementation\n",
    "\n",
    "\n",
    "| Sample   | Theta 0 Ini | Theta 1 Ini | Theta 0 Fin  | Theta 1 Fin | Steps | eps  | alpha | time   | Error    | J minus E | Ini J    | Iter |\n",
    "| -------- | ----------- | ----------- | ------------ | ----------- | ----- | ---- | ----- | ------ | -------- | --------- | -------- | ---- |\n",
    "| 100      | 0.84749002  | 0.76545551  | \\-2.9354679  | 43.00882074 | 25    | 0.01 | 0.01  | 316ms  | 139865.5 | 0.077732  | 322949.9 | 94   |\n",
    "| 1000     | 0.35807687  | 0.90481815  | 0.72234296   | 82.07779906 | 25    | 0.01 | 0.01  | 388ms  | 2110144  | 5509918   | 7620063  | 13   |\n",
    "| 10000    | 0.29877773  | 0.95662139  | \\-0.98469815 | 8.98194662  | 25    | 0.01 | 0.01  | 760ms  | 12271438 | 672314.7  | 12943753 | 2    |\n",
    "| 100000   | 0.57125933  | 0.78206484  | \\-0.42785141 | 80.49694913 | 25    | 0.01 | 0.01  | 4.67s  | 1.23E+08 | 6.13E+08  | 7.36E+08 | 1    |\n",
    "| 1000000  | 0.0847954   | 0.39305143  | 0.52290853   | 80.26752228 | 25    | 0.01 | 0.01  | 47.2s  | 1.22E+09 | 6.53E+09  | 7.75E+09 | 1    |\n",
    "| 10000000 | 0.14385065  | 0.6742215   | 0.64983568   | 75.68272054 | 25    | 0.01 | 0.01  | 7m 41s | 1.22E+10 | 5.6E+10   | 6.82E+10 | 1    |\n",
    "\n",
    "#### Implementing mini_batch gradient descent, gives less number of iterations as well as time required is less compared to batch and stochastic algorithm.\n",
    "#### Batch size: 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def Gradient_Method_Ex2(alpha, x, y, eps=0.0001, max_iter=1000, steps=10):\n",
    "    HasConverged = False\n",
    "    iter = 0\n",
    "    m = x.shape[0] # number of samples    \n",
    "    \n",
    "    print(\"Number of Samples:\", m)\n",
    "\n",
    "    # initial value for theta  : chosen randomly\n",
    "    # Theta=(Theta0[0],Theta1[0]) in IR^2\n",
    "    # Theta0[0] -> t0 in IR\n",
    "    # Theta1[0] -> t1 in IR\n",
    "    t0 = np.random.random(x.shape[1])\n",
    "    t1 = np.random.random(x.shape[1])\n",
    "    print(\"Initial Value of Thetao[0] =\", t0)\n",
    "    print(\"Initial Value of Theta1[0] =\", t1)\n",
    "\n",
    "    # The total error, J(theta)  is defined as\n",
    "    J = sum([(t0 + t1*x[i] - y[i])**2 for i in range(m)])\n",
    "    print(\"Total Initial Error J: \", J)\n",
    "\n",
    "    # The Iteration Loop\n",
    "    while not HasConverged:\n",
    "        # for each training sample, compute the gradient (d/d_theta j(theta))\n",
    "        # following: \n",
    "        \n",
    "        for i in range(0, m, m//10):\n",
    "            for j in range(i, i+(m//10)):\n",
    "                grad0 = 0.1 * sum([(t0 + t1*x[j] - y[j])]) \n",
    "                grad1 = 0.1 * sum([(t0 + t1*x[j] - y[j])*x[j]])\n",
    "\n",
    "                # We update the theta_temp\n",
    "                temp0 = t0 - alpha * grad0        \n",
    "                temp1 = t1 - alpha * grad1\n",
    "\n",
    "\n",
    "                # We update theta\n",
    "                t0 = temp0\n",
    "                t1 = temp1\n",
    "\n",
    "        # We compute Mean Squared Error\n",
    "        e = sum([(t0 + t1*x[i] - y[i])**2 for i in range(m)]) \n",
    "\n",
    "        if abs(J-e) <= eps:\n",
    "            print('Converged, iterations: ', iter)\n",
    "            HasConverged = True\n",
    "\n",
    "        if (iter % steps ==0): print(\"Iter: \", iter, \n",
    "                                     \" Error:\",e, \n",
    "                                     \" J-e:\",abs(J-e))    \n",
    "\n",
    "        J = e      # We update error \n",
    "        iter += 1  # We update iter\n",
    "\n",
    "        if iter == max_iter:\n",
    "            print('Max interactions exceeded!')\n",
    "            converged = True\n",
    "\n",
    "    return t0,t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape = (10000000, 1) y.shape = (10000000,)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "#   We create the Data     \n",
    "    x, y = make_regression(n_samples=10000000, n_features=1, n_informative=1, \n",
    "                        random_state=0, noise=35) \n",
    "    print('x.shape = %s y.shape = %s' %(x.shape, y.shape))    \n",
    "    \n",
    "# We choose some hyperparameters  \n",
    "    alpha = 0.01 # learning rate\n",
    "    ep = 0.01 # convergence criteria     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples: 10000000\n",
      "Initial Value of Thetao[0] = [0.14385065]\n",
      "Initial Value of Theta1[0] = [0.6742215]\n",
      "Total Initial Error J:  [6.82250468e+10]\n",
      "Iter:  0  Error: [1.22498444e+10]  J-e: [5.59752023e+10]\n",
      "Converged, iterations:  1\n",
      "Computed value\n",
      "Theta0 = [0.64983568]       Theta1 = [75.68272054]\n",
      "Intercept = -0.0024287020354418695 Slope = 75.51124926556906\n",
      "Error on Slope [-0.17147127]\n",
      "Error on Intercept [-0.65226438]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well Done!\n",
      "Wall time: 7min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# We call gradient descent, this gives approximation \n",
    "# of theta0 and theta1\n",
    "\n",
    "\n",
    "theta0, theta1 = Gradient_Method_Ex2(alpha, x, y, ep, max_iter=1000,\n",
    "                                     steps=25)\n",
    "print(\"Computed value\")\n",
    "print(('Theta0 = %s       Theta1 = %s') %(theta0, theta1)) \n",
    "\n",
    "# We check a good approximation of the \"exact\" value\n",
    "# with scipy linear regression \n",
    "slope, intercept, r_value, p_value, slope_std_error = stats.linregress(x[:,0], y)\n",
    "print(('Intercept = %s Slope = %s') %(intercept, slope))\n",
    "print(\"Error on Slope\", slope-theta1)\n",
    "print(\"Error on Intercept\", intercept-theta0)\n",
    "    \n",
    "# We plot  the data and the line we have computed, i.e.: Y= Theta0 + Theta1 * X\n",
    "for i in range(x.shape[1]):\n",
    "        y_predict = theta0 + theta1*x \n",
    "\n",
    "pylab.plot(x,y,'o')\n",
    "pylab.plot(x,y_predict,'k-')\n",
    "pylab.show()\n",
    "print(\"Well Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
